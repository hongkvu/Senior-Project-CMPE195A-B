{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongkvu/Senior-Project-CMPE195A-B/blob/main/flower_category.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "IINd0XdzFbib",
        "outputId": "9eae18dc-59de-4454-ae5a-d3c181f57284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.8/dist-packages (0.4.1)\n",
            "Collecting argparse\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Requirement already satisfied: ws4py in /usr/local/lib/python3.8/dist-packages (from anvil-uplink) (0.5.1)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install anvil-uplink\n",
        "import anvil.server\n",
        "anvil.server.connect(\"B3YS7YE3UJZDPLRZR5O3MKNO-YV6ZQAAZVBPTTRUB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrWxbd3scK4y",
        "outputId": "e7d3c416-ce5b-41f6-db8b-dd815d6e9de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  3 00:53:17 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   28C    P0    47W / 400W |   1140MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Naaamk5SqFbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dfb8912-ccc6-4401-9c63-dc6efed79984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxCZqgQ9ciC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b33bbd5-597d-4359-adb7-307a05086126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.50.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.19.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.28.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (22.11.23)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.12.1+cu111 (from versions: 1.4.0, 1.4.0+cpu, 1.4.0+cu100, 1.4.0+cu92, 1.5.0, 1.5.0+cpu, 1.5.0+cu101, 1.5.0+cu92, 1.5.1, 1.5.1+cpu, 1.5.1+cu101, 1.5.1+cu92, 1.6.0, 1.6.0+cpu, 1.6.0+cu101, 1.6.0+cu92, 1.7.0, 1.7.0+cpu, 1.7.0+cu101, 1.7.0+cu110, 1.7.0+cu92, 1.7.1, 1.7.1+cpu, 1.7.1+cu101, 1.7.1+cu110, 1.7.1+cu92, 1.7.1+rocm3.7, 1.7.1+rocm3.8, 1.8.0, 1.8.0+cpu, 1.8.0+cu101, 1.8.0+cu111, 1.8.0+rocm3.10, 1.8.0+rocm4.0.1, 1.8.1, 1.8.1+cpu, 1.8.1+cu101, 1.8.1+cu102, 1.8.1+cu111, 1.8.1+rocm3.10, 1.8.1+rocm4.0.1, 1.9.0, 1.9.0+cpu, 1.9.0+cu102, 1.9.0+cu111, 1.9.0+rocm4.0.1, 1.9.0+rocm4.1, 1.9.0+rocm4.2, 1.9.1, 1.9.1+cpu, 1.9.1+cu102, 1.9.1+cu111, 1.9.1+rocm4.0.1, 1.9.1+rocm4.1, 1.9.1+rocm4.2, 1.10.0, 1.10.0+cpu, 1.10.0+cu102, 1.10.0+cu111, 1.10.0+cu113, 1.10.0+rocm4.0.1, 1.10.0+rocm4.1, 1.10.0+rocm4.2, 1.10.1, 1.10.1+cpu, 1.10.1+cu102, 1.10.1+cu111, 1.10.1+cu113, 1.10.1+rocm4.0.1, 1.10.1+rocm4.1, 1.10.1+rocm4.2, 1.10.2, 1.10.2+cpu, 1.10.2+cu102, 1.10.2+cu111, 1.10.2+cu113, 1.10.2+rocm4.0.1, 1.10.2+rocm4.1, 1.10.2+rocm4.2, 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch==1.12.1+cu111\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu\n",
        "!pip install einops\n",
        "!pip install torch==1.12.1+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vicqxW7wnfwX"
      },
      "source": [
        "CoAtNet src code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRoadqXyOFlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6c13b6-729d-4afa-fbd9-8b0af17bdd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000]) 17789624\n",
            "torch.Size([1, 1000]) 33170624\n",
            "torch.Size([1, 1000]) 55767564\n",
            "torch.Size([1, 1000]) 117724480\n",
            "torch.Size([1, 1000]) 203960368\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "# \tnn.Conv2d : Applies a 2D convolution over an input signal composed of several input planes.\n",
        "\n",
        "def conv_3x3_bn(inp, oup, image_size, downsample=False):\n",
        "    stride = 1 if downsample == False else 2\n",
        "    return nn.Sequential(                               # build neural networks \n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),  # slide a matrix or filter over 2D data\n",
        "        nn.BatchNorm2d(oup),  # Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) \n",
        "        nn.GELU() # The Gaussian Error Linear Unit is an activation function.\n",
        "    )\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn, norm):\n",
        "        super().__init__()    # initializes the parent class object into the child class\n",
        "        self.norm = norm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class SE(nn.Module):\n",
        "    def __init__(self, inp, oup, expansion=0.25):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)                 #Sets the output size of the pooling layer to 1x1\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(oup, int(inp * expansion), bias=False),   #applies a linear transformation\n",
        "            nn.GELU(),        #applies the Gaussian Error Linear Units function\n",
        "            nn.Linear(int(inp * expansion), oup, bias=False),\n",
        "            nn.Sigmoid()      # An activation function that takes a value and turns it into a value between 0 and 1 to predict probabilities.\n",
        "        )\n",
        "\n",
        "    def forward(self, x):               # define the flow of forward process \n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c) # Squeeze - perform Global Average Pooling\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim), #applies a linear transformation\n",
        "            nn.GELU(),       #applies the Gaussian Error Linear Units function\n",
        "            nn.Dropout(dropout),  # takes in the dropout rate\n",
        "            # to Prevent Neural Networks from Overfitting because it increase accuracy\n",
        "            nn.Linear(hidden_dim, dim),   #applies a linear transformation\n",
        "            nn.Dropout(dropout) # takes in the dropout rate\n",
        "        )\n",
        "    # define the flow of forward process \n",
        "    def forward(self, x):             # x in the forward() method is the input vector.\n",
        "        return self.net(x)\n",
        "\n",
        "# A MBConv is a Inverted Linear BottleNeck layer with Depth-Wise Separable Convolution.\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample    # reducing the sampling rate of a signal.\n",
        "        stride = 1 if self.downsample == False else 2\n",
        "        hidden_dim = int(inp * expansion)   # Number of hidden layers self.\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool = nn.MaxPool2d(3, 2, 1)   # Applies a 2D max pooling over an input signal composed of several input planes.\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        if expansion == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,    # build neural networks that slide a matrix or filter over 2D data\n",
        "                          1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),                     # Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) \n",
        "                nn.GELU(),                                      #applies the Gaussian Error Linear Units function\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False), # build neural networks that slide a matrix or filter over 2D data\n",
        "                nn.BatchNorm2d(oup),                             # Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) \n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                # down-sample in the first conv\n",
        "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),    # build neural networks that slide a matrix or filter over 2D data\n",
        "                nn.BatchNorm2d(hidden_dim),                              # Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension)\n",
        "                nn.GELU(),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
        "                          groups=hidden_dim, bias=False),                # build neural networks that slide a matrix or filter over 2D data\n",
        "                nn.BatchNorm2d(hidden_dim),                              # Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension)\n",
        "                nn.GELU(),                                               #applies the Gaussian Error Linear Units function\n",
        "                SE(inp, hidden_dim),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),         # build neural networks that slide a matrix or filter over 2D data\n",
        "                nn.BatchNorm2d(oup),                                     # Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension)\n",
        "            ) \n",
        "        \n",
        "        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n",
        "\n",
        "    def forward(self, x):           # define the flow of forward process\n",
        "        if self.downsample:\n",
        "            return self.proj(self.pool(x)) + self.conv(x)\n",
        "        else:\n",
        "            return x + self.conv(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == inp)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        # parameter table of relative position bias\n",
        "        self.relative_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
        "\n",
        "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
        "        coords = torch.flatten(torch.stack(coords), 1)\n",
        "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
        "\n",
        "        relative_coords[0] += self.ih - 1\n",
        "        relative_coords[1] += self.iw - 1\n",
        "        relative_coords[0] *= 2 * self.iw - 1\n",
        "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
        "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
        "        self.register_buffer(\"relative_index\", relative_index)\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, oup),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(\n",
        "            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        # Use \"gather\" for more efficiency on GPUs\n",
        "        relative_bias = self.relative_bias_table.gather(\n",
        "            0, self.relative_index.repeat(1, self.heads))\n",
        "        relative_bias = rearrange(\n",
        "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
        "        dots = dots + relative_bias\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.to_out(out)\n",
        "        return out\n",
        "\n",
        "# Transformer architecture implements an encoder-decoder structure without recurrence and convolutions in order to generate an output.\n",
        "# A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data.\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
        "        super().__init__()\n",
        "        hidden_dim = int(inp * 4)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "        self.downsample = downsample\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)     # attention technique\n",
        "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
        "\n",
        "        self.attn = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(inp, self.attn, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "        )\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),  # # concatenated images along horizontal axis\n",
        "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)   # space-to-depth operation\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample:\n",
        "            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x))\n",
        "        else:\n",
        "            x = x + self.attn(x)\n",
        "        x = x + self.ff(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CoAtNet(nn.Module):\n",
        "    def __init__(self, image_size, in_channels, num_blocks, channels, num_classes=1000, block_types=['C', 'C', 'T', 'T']):\n",
        "        super().__init__()\n",
        "        ih, iw = image_size\n",
        "        block = {'C': MBConv, 'T': Transformer}\n",
        "\n",
        "        self.s0 = self._make_layer(\n",
        "            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
        "        self.s1 = self._make_layer(\n",
        "            block[block_types[0]], channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
        "        self.s2 = self._make_layer(\n",
        "            block[block_types[1]], channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
        "        self.s3 = self._make_layer(\n",
        "            block[block_types[2]], channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
        "        self.s4 = self._make_layer(\n",
        "            block[block_types[3]], channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
        "\n",
        "        self.pool = nn.AvgPool2d(ih // 32, 1)\n",
        "        self.fc = nn.Linear(channels[-1], num_classes, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.s0(x)\n",
        "        x = self.s1(x)\n",
        "        x = self.s2(x)\n",
        "        x = self.s3(x)\n",
        "        x = self.s4(x)\n",
        "\n",
        "        x = self.pool(x).view(-1, x.shape[1])\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, inp, oup, depth, image_size):\n",
        "        layers = nn.ModuleList([])\n",
        "        for i in range(depth):\n",
        "            if i == 0:\n",
        "                layers.append(block(inp, oup, image_size, downsample=True))\n",
        "            else:\n",
        "                layers.append(block(oup, oup, image_size))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def coatnet_0():\n",
        "    num_blocks = [2, 2, 3, 5, 2]            # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def coatnet_1():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def coatnet_2():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [128, 128, 256, 512, 1026]   # D\n",
        "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def coatnet_3():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def coatnet_4():\n",
        "    num_blocks = [2, 2, 12, 28, 2]          # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "\n",
        "#PyTorch doesn't have a function to calculate the total number of parameters as Keras does, \n",
        "#but it's possible to sum the number of elements for every parameter group\n",
        "#trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    img = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "    net = coatnet_0()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatnet_1()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatnet_2()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatnet_3()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatnet_4()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3_0uboVgIjK"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R9urY7HPJFr"
      },
      "outputs": [],
      "source": [
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjs9-UoHgMuy"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim #optimizer, will hold the current state and will update the parameters based on the computed gradients\n",
        "import torch\n",
        "import torch.nn as nn #neural network framework\n",
        "import torch.nn.parallel \n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms #common image transformation\n",
        "from torch.autograd import Variable #automatic differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTtlySbjuYo1"
      },
      "source": [
        "Set global parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0-0c34UuT6c"
      },
      "outputs": [],
      "source": [
        "modellr = 1e-4\n",
        "BATCH_SIZE = 16 #the dataset is divided into batches, each of 16 \n",
        "EPOCHS = 5 #number of times the entire dataset is passed through the neural network\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')#the GPU device that operations will be on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSQv_16ouUZJ"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgakdXjSuUED"
      },
      "outputs": [],
      "source": [
        "#modifying images (resize, convert, normalize)  \n",
        "transform = transforms.Compose([ #chain the transformation together\n",
        "    transforms.Resize((224, 224)), #resize image\n",
        "    transforms.ToTensor(), #convert image to a tensor (matrix)\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) #normalize with (mean, standard deviation)\n",
        "\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywyF1Q0gutu7"
      },
      "source": [
        "Fetch the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F6o8vK8heGT"
      },
      "outputs": [],
      "source": [
        "# coding:utf8\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "from torchvision import transforms as T\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "Labels = {\n",
        "     'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip':4\n",
        "}\n",
        " \n",
        "class FlowerData (data.Dataset):\n",
        " \n",
        "    def __init__(self, root, transforms=None, train=True, test=False):\n",
        "        \"\"\"\n",
        "        Main objective: to obtain the addresses of all pictures and divide the data according to training, verification and test\n",
        "        \"\"\"\n",
        "        self.test = test\n",
        "        self.transforms = transforms\n",
        " \n",
        "        if self.test:\n",
        "            imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
        "            self.imgs = imgs\n",
        "        else:\n",
        "            imgs_labels = [os.path.join(root, img) for img in os.listdir(root)]\n",
        "            imgs = []\n",
        "            for imglable in imgs_labels:\n",
        "                for imgname in os.listdir(imglable):\n",
        "                    imgpath = os.path.join(imglable, imgname)\n",
        "                    imgs.append(imgpath)\n",
        "            trainval_files, val_files = train_test_split(imgs, test_size=0.3, random_state=42)\n",
        "            if train:\n",
        "                self.imgs = trainval_files\n",
        "            else:\n",
        "                self.imgs = val_files\n",
        " \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Returns the data of one picture at a time\n",
        "        \"\"\"\n",
        "        img_path = self.imgs[index]\n",
        "        img_path=img_path.replace(\"\\\\\",'/')\n",
        "        if self.test:\n",
        "            label = -1\n",
        "        else:\n",
        "            labelname = img_path.split('/')[-2]\n",
        "            label = Labels[labelname]\n",
        "        data = Image.open(img_path).convert('RGB')\n",
        "        data = self.transforms(data)\n",
        "        return data, label\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRLFjDcvIlPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19be4418-382d-47b6-ffb9-b13de55037d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.8/dist-packages (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# split-data\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "import pathlib\n",
        "data = \"drive/My Drive/195A+BSeniorProjectGroupWorks/Datasets/Flower_Dataset/flowers\"\n",
        "data_splitted = \"drive/My Drive/195A+BSeniorProjectGroupWorks/Datasets/Flower_Dataset/splitted_datasets\"\n",
        "# splitfolders.ratio(data, data_splitted, seed=1337, ratio=(.8, .1, .1)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDzDg43wLW6s"
      },
      "outputs": [],
      "source": [
        "# Read data\n",
        "# Suggestion: automates image look-up/download from the web\n",
        "dataset_train = FlowerData(pathlib.Path(data_splitted)/\"train\", transforms=transform, train=True)\n",
        "dataset_test = FlowerData(pathlib.Path(data_splitted)/\"val\", transforms=transform_test, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4ZIJhf9u3LS"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnza0JBEu4Mg"
      },
      "source": [
        "Set model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwuosvXaqPC_"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model and move to the GPU\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_ft = coatnet_0()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 200) #change the 2nd arg according to the number of Labels\n",
        "#TODO: look into why changing this arg fixes the error\n",
        "model_ft.to(DEVICE)#move the model to GPU\n",
        "# Choose the simple and violent Adam optimizer to reduce the learning rate\n",
        "optimizer = optim.Adam(model_ft.parameters(), lr=modellr)\n",
        "cosine_schedule = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer,T_max=20,eta_min=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7slfcWv9qV-A"
      },
      "outputs": [],
      "source": [
        "# Define training process\n",
        "### UNCOMMENT AND RUN THIS CELL AND THE ONE BELOW IF TRAINING NEEDED\n",
        "### OTHERWISE, A SAVED MODEL WILL BE LOADED FROM drive/My Drive/coatnet.pt\n",
        "# def train(model, device, train_loader, optimizer, epoch):\n",
        "#     model.train()#set the mode to train mode, not actually training using this function\n",
        "#     sum_loss = 0\n",
        "#     total_num = len(train_loader.dataset)\n",
        "#     print(total_num, len(train_loader))\n",
        "#     for batch_idx, (data, target) in enumerate(train_loader):#enumrate is a counter for the loop\n",
        "#         data, target = Variable(data).to(device), Variable(target).to(device)#send data\n",
        "#         output = model(data)\n",
        "#         loss = criterion(output, target)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         print_loss = loss.data.item()\n",
        "#         sum_loss += print_loss\n",
        "#         if (batch_idx + 1) % 10 == 0:\n",
        "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "#                 epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "#                        100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "#     ave_loss = sum_loss / len(train_loader)\n",
        "#     print('epoch:{},loss:{}'.format(epoch, ave_loss))\n",
        "\n",
        "\n",
        "# # Verification process\n",
        "# def val(model, device, test_loader):\n",
        "#     model.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     total_num = len(test_loader.dataset)\n",
        "#     print(total_num, len(test_loader))\n",
        "#     with torch.no_grad():\n",
        "#         for data, target in test_loader:\n",
        "#             data, target = Variable(data).to(device), Variable(target).to(device)\n",
        "#             output = model(data)\n",
        "#             loss = criterion(output, target)\n",
        "#             _, pred = torch.max(output.data, 1)\n",
        "#             correct += torch.sum(pred == target)\n",
        "#             print_loss = loss.data.item()\n",
        "#             test_loss += print_loss\n",
        "#         correct = correct.data.item()\n",
        "#         acc = correct / total_num\n",
        "#         avgloss = test_loss / len(test_loader)\n",
        "#         print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "#             avgloss, correct, len(test_loader.dataset), 100 * acc))\n",
        "\n",
        "\n",
        "# # train\n",
        "\n",
        "# for epoch in range(1, EPOCHS + 1):\n",
        "#     train(model_ft, DEVICE, train_loader, optimizer, epoch)\n",
        "#     cosine_schedule.step()\n",
        "#     val(model_ft, DEVICE, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IayLZyd8JEz"
      },
      "outputs": [],
      "source": [
        "# torch.save(model_ft, 'model.pth')\n",
        "#save the training into .pt\n",
        "### UNCOMMENT AND RUN THIS CELL IF JUST TRAINED AND SAVING NEEDED\n",
        "### OTHERWISE, A SAVED MODEL WILL BE LOADED FROM drive/My Drive/coatnet.pt\n",
        "# path = 'drive/My Drive/coatnet.pt'\n",
        "# torch.save(model_ft, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4KGuLZ3h_M"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUk-Aq0o3jmj"
      },
      "outputs": [],
      "source": [
        "classes = (\n",
        "     'daisy', 'dandelion', 'rose', 'sunflower', 'tulip'\n",
        ")\n",
        "     \n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Bl6wuo3l6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbab400-a521-4589-d059-0bebea6ea380"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CoAtNet(\n",
              "  (s0): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU(approximate=none)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU(approximate=none)\n",
              "    )\n",
              "  )\n",
              "  (s1): Sequential(\n",
              "    (0): MBConv(\n",
              "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (proj): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (conv): PreNorm(\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (fn): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate=none)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate=none)\n",
              "          (6): SE(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=16, bias=False)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Linear(in_features=16, out_features=256, bias=False)\n",
              "              (3): Sigmoid()\n",
              "            )\n",
              "          )\n",
              "          (7): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (conv): PreNorm(\n",
              "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (fn): Sequential(\n",
              "          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate=none)\n",
              "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate=none)\n",
              "          (6): SE(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc): Sequential(\n",
              "              (0): Linear(in_features=384, out_features=24, bias=False)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Linear(in_features=24, out_features=384, bias=False)\n",
              "              (3): Sigmoid()\n",
              "            )\n",
              "          )\n",
              "          (7): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (s2): Sequential(\n",
              "    (0): MBConv(\n",
              "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (proj): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (conv): PreNorm(\n",
              "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (fn): Sequential(\n",
              "          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate=none)\n",
              "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate=none)\n",
              "          (6): SE(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc): Sequential(\n",
              "              (0): Linear(in_features=384, out_features=24, bias=False)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Linear(in_features=24, out_features=384, bias=False)\n",
              "              (3): Sigmoid()\n",
              "            )\n",
              "          )\n",
              "          (7): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (conv): PreNorm(\n",
              "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (fn): Sequential(\n",
              "          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate=none)\n",
              "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate=none)\n",
              "          (6): SE(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc): Sequential(\n",
              "              (0): Linear(in_features=768, out_features=48, bias=False)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Linear(in_features=48, out_features=768, bias=False)\n",
              "              (3): Sigmoid()\n",
              "            )\n",
              "          )\n",
              "          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (conv): PreNorm(\n",
              "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (fn): Sequential(\n",
              "          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate=none)\n",
              "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate=none)\n",
              "          (6): SE(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc): Sequential(\n",
              "              (0): Linear(in_features=768, out_features=48, bias=False)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Linear(in_features=48, out_features=768, bias=False)\n",
              "              (3): Sigmoid()\n",
              "            )\n",
              "          )\n",
              "          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (s3): Sequential(\n",
              "    (0): Transformer(\n",
              "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (proj): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (attn): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=192, out_features=768, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
              "              (1): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=384, out_features=768, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=768, out_features=384, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "    )\n",
              "    (1): Transformer(\n",
              "      (attn): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
              "              (1): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "    )\n",
              "    (2): Transformer(\n",
              "      (attn): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
              "              (1): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "    )\n",
              "    (3): Transformer(\n",
              "      (attn): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
              "              (1): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "    )\n",
              "    (4): Transformer(\n",
              "      (attn): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
              "              (1): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (s4): Sequential(\n",
              "    (0): Transformer(\n",
              "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (proj): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (attn): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=768, bias=True)\n",
              "              (1): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=768, out_features=1536, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=1536, out_features=768, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n",
              "      )\n",
              "    )\n",
              "    (1): Transformer(\n",
              "      (attn): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=256, out_features=768, bias=True)\n",
              "              (1): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=768, out_features=200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#load the model and put model in DEVICE\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#model = torch.load(\"model.pth\")\n",
        "#load the model from .pt\n",
        "path = 'drive/My Drive/coatnet.pt'\n",
        "model = torch.load(path)\n",
        "model.eval()\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGMv6nQij6VQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install anvil\n",
        "import anvil\n",
        "\n",
        "@anvil.server.callable\n",
        "def predict_flower(file):\n",
        "  # folder = 'drive/MyDrive/input_files'\n",
        "  image = 'drive/My Drive/input_files/'+file\n",
        "  img = Image.open(image)\n",
        "  img = transform_test(img)\n",
        "  img.unsqueeze_(0)\n",
        "  img = Variable(img).to(DEVICE)\n",
        "  out = model(img)\n",
        "  # Predict\n",
        "  _, pred = torch.max(out.data, 1)\n",
        "  return classes[pred.data.item()]\n",
        "#testing useing test set\n",
        "# path = 'drive/MyDrive/195A+BSeniorProjectGroupWorks/Datasets/Flower_Dataset/flowers_train_test_set/test/sunflower/'\n",
        "# testList = os.listdir(path)\n",
        "# for file in testList:\n",
        "#     img = Image.open(path + file)\n",
        "#     img = transform_test(img)\n",
        "#     img.unsqueeze_(0)\n",
        "#     img = Variable(img).to(DEVICE)\n",
        "#     out = model(img)\n",
        "#     # Predict\n",
        "#     _, pred = torch.max(out.data, 1)\n",
        "#     print('Image Name: {}, predict: {}'.format(file, classes[pred.data.item()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rz9q33FH62S"
      },
      "outputs": [],
      "source": [
        "#anvil.server.wait_forever()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Labels = {\n",
        "#     'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip':4\n",
        "# }\n",
        "\n",
        "@anvil.server.callable\n",
        "def flower_information(name):\n",
        "  if (name == 'daisy'):\n",
        "    path()\n",
        "    return 'Here is some Daisy pictures'\n",
        "  elif (name == 'rose'):\n",
        "    return ''\n",
        "  elif (name == 'sunflower'):\n",
        "      return ''\n",
        "  elif(name == 'tulip'):\n",
        "    return ''\n",
        "  elif (name == 'dandelion'):\n",
        "    return 'Dandelion here'\n",
        "\n",
        "  \n",
        "      \n"
      ],
      "metadata": {
        "id": "YeRXNGklqzVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qMt3cx24gl9"
      },
      "source": [
        "Note: larger dataset yields worse result\n",
        "Why?\n",
        "*Figure this out and make it a novelty point* \n",
        "\n",
        "Priority: expand dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGeBpzyJ8sgk"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# import urllib.request as ur\n",
        "# @anvil.server.callable\n",
        "# def wiki_search(text):\n",
        "#   input = text.split(' ')\n",
        "#   input = '+'.join(text)\n",
        "#   # you can change www.bing.com to any search engine except google.\n",
        "#   googlesearch = 'https://en.wikipedia.org/wiki/' + input\n",
        "#   source = ur.urlopen(googlesearch)\n",
        "#   source = source.read()\n",
        "#   source = str(source)        \n",
        "#   output = re.findall(r'''(?:http://|www.)[^\"]+''', source)\n",
        "#   firstLink = output[0]\n",
        "#   print(firstLink)\n",
        "#   return firstLink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdbrQxr0BRtq"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# import urllib.request as ur\n",
        "\n",
        "# print('What would you like to look up?')\n",
        "# text = input('::')\n",
        "# search_string = text.split(' ')\n",
        "# search_string = '+'.join(search_string)\n",
        "# # you can change www.bing.com to any search engine except google.\n",
        "# googlesearch = 'https://en.wikipedia.org/wiki/' + search_string\n",
        "# source = ur.urlopen(googlesearch)\n",
        "# source = source.read()\n",
        "# source = str(source)        \n",
        "# output = re.findall(r'''(?:http://|www.)[^\"]+''', source)\n",
        "# for i in range(len(output)):\n",
        "#     print(output[i])\n",
        "\n",
        "# firstLink = output[0]\n",
        "# print(firstLink)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install wikipedia-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qmpz1-9xahb",
        "outputId": "f9023c45-1aea-4bb0-fde9-039fe4f332ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.8/dist-packages (0.5.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from wikipedia-api) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "@anvil.server.callable\n",
        "def wiki_search_api(keyword):\n",
        "  wiki_wiki = wikipediaapi.Wikipedia('en')\n",
        "  page_py = wiki_wiki.page(keyword)\n",
        "  return page_py.summary[0:2000]"
      ],
      "metadata": {
        "id": "ARsuDWgpxhdj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}